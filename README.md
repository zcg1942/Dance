# 实验环境

C++使用的编程环境为visual Studio 2013，OpenCV3.2

Python编程环境为PyCharm Community 2017，解释器为Python 3.6，主要的工具库为OpenCV3.4.6+contrib

# 获得显著性图像

使用IG，也就是FT显著性区域提取算法，通过Lab颜色空间利用了图像的亮度和色彩信息，计算得到每个像素的显著性。显著性图像表现为灰度图像，像素点的显著性值与灰度值大小成正比。

Achanta发表在CVPR 2009的原文[《Frequency-tuned Salient Region Detection 》][链接]

[链接]: https://ivrlwww.epfl.ch/supplementary_material/RK_CVPR09/

运行程序时，在项目根目录下输入名为“bike1.bmp”的图像，输出结果为“salImage.bmp”。如果在期间读取图像失败，那么在控制台窗口会出现"图像没有读取成功" 的提示。

无论输入图像是色彩图像还是灰度图像，都要转换为三通道图像。如果是灰度图像，先转换为BGR三通道图像，再转换在Lab颜色空间上的图像。然后分别得到L、a、b三个通道上的均值。对于每一个像素，在Lab的三个分量上计算均方差的平方根，得到显著性值。为了之后归一化在灰度值的范围内，记录了显著性值的最大值和最小值。

相关文件见SalientRegionGenerate文件夹。

# 属性表

在重新打开解决方案时出现了加载失败的提示，这种错误在移植其他人的代码时也会出现，主要原因是电脑机器的环境出现了变化，包括vs，opencv等。我这里就是将opencv的属性表的文件位置移动了，造成了找不到属性表，所以加载失败。opencv的属性表是为了方便整体修改工程的配置属性，分为debug版本和release版本。属性表中包括了库目录、包含目录和附加依赖项等信息，这些信息与每台机器的opencv安装位置有关，所以需要自己生成。生成方法可以参考如下链接: https://blog.csdn.net/bendanban/article/details/28661763

# SIFT图像配准

SIFT特征点的检测与匹配使用Rob Hess提供的c语言源码。特征点检测时的输入图像应该是提前生成的显著性灰度图像，通过修改项目的属性页实现。具体做法是修改配置属性中的调试选项中的命令参数，填入根目录下的两个显著性图像的名称（包括后缀名）。

通过显著性图像估计出的单应矩阵可以完美适用于原始图像的透视变换，从而完成图像配准。这时需要重新读入原始图像（在match.c文件的144和145行处读入原始图像）。

在运行过程中，控制台会打印输出每个图像上检测得到的特征点数目，可以看到，一般情况下两幅图像中检测到的特征点数目是不同的。事实上，检测出特征点之后的检索与匹配与图像检索和匹配技术中的很多内容是相同的，在看一篇知乎专栏中提到了可以对两幅图像的特征点在数目上做归一化，使得不同图像的特征点数目和每个特征点的维度都是一致的。https://zhuanlan.zhihu.com/p/46735159

此外，该程序还会打印出估计出的单应矩阵，会计算特征点之间的均方根误差RMSE，配准后的图像与参考图像之间的峰值信噪比PSNR，会统计出特征点检测的耗时和整个程序的耗时。在match.c文件的213行处会将配准后的图像保存在E盘，保存的文件路径和名称可以自行修改。

相关文件见SIFT文件夹。

# 图像减法

以往的图像压缩都是基于单幅图像的压缩，去除图像中的冗余信息。在图像集的构建过程中可能会存在内容相似的图像，这些图像经过图像像素级别的减法就可以得到具有稀疏性的矩阵，从而有利于图像压缩。而图像配准的目的就是使得配准之后的图像与参考图像尽可能相似，图像配准与图像减法、图像压缩技术结合起来就可以实现对参考图像的大压缩比无损压缩。

为了形象化地表示经过图像减法之后的效果，这里可以使用OpenCV函数absdiff只记录差值的绝对值或者借助Mat的data属性在相减时取绝对值，将其作为差值图像的灰度值。Mat类型的step属性，表示矩阵每一行元素所占的字节数。

若使用OpenCV中的substract函数，小于0的部分会被截断为0值。

在实际处理中必须知道差值图像每个像素点处的正负性。如果简单地将取绝对值函数abd去掉，需要注意输入图像的元素类型是uchar，差值元素的类型不能再选取为uchar。
```C++
uchar a = 255;
uchar b = 3;
uchar c = b - a;
cout << "c=" << c << endl;
```

```c++
uchar a = 255;
uchar b = 3;
int c = b - a;
```

得到的Mat在可以按照如下公式进行归一化的：
$$
(p-min)*255/(max-min)
$$
上式中 $p$ 指的是Mat矩阵中的元素，$min$和$max$分别是其中的最小值和最大值。

还有一种方法是在保存时将其正负性直接保存下来，这样就不能采用imwrite保存图像的方法，可以使用FileStorage的方法，将图像保存成xml格式。

得到的差值图像可以从灰度直方图的角度体现出矩阵的稀疏性。求取图像的直方图使用Python实现，见hist.py文件。

这里选取了利用Python中的numpy将图像转换成数组，然后直接相减的方法，有利于后续直接调用Python中zlib压缩模块进行压缩。

# 图像压缩

正如上文提到的，压缩使用了zlib库。这是一个高效、跨平台的数据压缩库，主要使用的编码方法是哈夫曼编码和LZ77编码。将图像转换成字节流或者数组进行压缩。相关代码见pycompress.py文件。

# 差异值哈希

采用了更具鲁棒性的差异值哈希算法。将图像归一化为8*9的大小，然后比较同一行相邻的元素大小，生成二进制的图像指纹，以十六进制表示。

相关文件见dHash.py文件。

























